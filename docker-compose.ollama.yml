version: '3'
services:
  ollama:
    container_name: ollama
    image: ollama/ollama
    volumes:
      - ./docker/ollama:/ollama  # Mount the directory containing entrypoint.sh
    ports:
      - 11434:11434
    entrypoint: ["/ollama/entrypoint.sh"]  # Specify the entrypoint script
    deploy:
      resources:
        reservations:
          devices:
            - capabilities: [gpu]

############################################################
## Pull Model
############################################################
# curl -X POST http://localhost:11434/api/pull -d '{
#   "name": "llama2:7b"
# }'

############################################################
## Get Model
############################################################
# curl http://localhost:11434/api/tags

############################################################
## Vector Embeddings
############################################################
# curl -X POST http://localhost:11434/api/embeddings -d '{
#   "model": "llama2:7b",
#   "prompt": "Here is an article about llamas..."
# }'

############################################################
## Query the model
############################################################
# curl -X POST http://localhost:11434/api/generate -d '{
#   "model": "llama2",
#   "prompt":"Why is the sky blue?"
# }'
